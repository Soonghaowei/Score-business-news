
import requests
from bs4 import BeautifulSoup
import urllib.request
import time
import random
def userAgent():
    user_agents = [
    "Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1",
    "Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)",
    "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5",
    "Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7",
    "Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14",
    "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14",
    "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1",
    "Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7",
    "Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10",
    "Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)",
    "Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)",
    "Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1",
    "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1",
    "Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre",
    "Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )", ]

    UserAgent = random.choice(user_agents)
    return UserAgent

def getIp():
    ip = [
        "http://55.67.160.0",
        "http://55.67.160.0",
        "http://55.67.160.0",
        # "http://204.16.1.182:3128",
        # "http://129.107.60.14:80",
        # "http://200.65.129.2:80",
        # "http://67.69.254.240:80",
        # "http://193.37.152.206:3128",
        # "http://169.235.24.133:3127",
        # "http://200.204.154.29:6588",
        # "http://200.174.85.195:3128",
        # "http://67.69.254.248:80",
        # "http://67.69.254.243:80",
        # "http://152.101.118.253:8080",
        # "http://189.112.246.145:8080",
        # "http://79.148.249.246:8080",
    ]

    IP = random.choice(ip)
    return IP

def getHTMLText(url):



            # agent='Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36'
            agent=userAgent()
            cookie='PHPSESSID=5cfisakcq2sut86i76imfpvh66; Hm_lvt_c4dff7ccd6927dc8132543b8752d3b53=1541468857; yunsuo_session_verify=a5c09fd6709b4b187686e2a43e5778a0; Hm_lpvt_c4dff7ccd6927dc8132543b8752d3b53=1541483841'
            refer='http://job.qsbdc.com/book_info.php?book_id=1167'
            headers={'User-Agent':agent,'Cookie':cookie,'Refer':refer}
            proxies =getIp()


            r = requests.get(url,headers)
            r.raise_for_status()
            r.encoding = 'utf-8'
            return r.text


def getRelativeUrl():
    # for p in range(1,100):
     # try:
        for i in range(971,1168):

            url = 'http://job.qsbdc.com/word_list.php?book_id=' + str(i)
            # print(url)
                # html = getHTMLText(url)
                #
                # soup = BeautifulSoup(html, "html.parser")
            newsHtml = requests.get(url)
            newsHtml.encoding = "utf-8"
            soup = BeautifulSoup(newsHtml.text, "html.parser")
            #22222
            # html = getHTMLText(url)
            # print(html)
            # soup = BeautifulSoup(html, "html.parser")
            title = soup.find('div',class_="r_title")
            print(title)
            # try:
            title = title.string

            f = open('Z:/Text-mining-for-trade/word_lists/' + title + '.txt', 'a+')
            print(url)

            time.sleep(5)
            print(time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()))
            # except:
            #     a=0
            # try:
            for j in range(1,20):
                    url1 = 'http://job.qsbdc.com/word_list.php?book_id=' + str(i)+'&&page_id='+str(j)
                # # return url1
                # getContentOfCom(url1)
                    newsHtml = requests.get(url1)
                    newsHtml.encoding = "utf-8"
                    soup = BeautifulSoup(newsHtml.text, "html.parser")
                    # html = getHTMLText(url1)
                    # html.encoding = "utf-8"
                    # print(html)
                    # soup = BeautifulSoup(html, "html.parser")
                # words = soup.find('span',class_='hidden_1_1')
                    words = soup.select('span.hidden_1_1')

                    try:
                     for word in words:
                        if len(word) > 0:
                            f.write(str(word.string))
                            f.write(str('\n'))
                    except:
                            a=0
            f.close()

            # except:
            #     return ""
def getContentOfCom(url1):

        newsHtml = requests.get(url1)
        # newsHtml.encoding = "utf-8"
        soup = BeautifulSoup(newsHtml.text, "html.parser")

        # words = soup.find('span',class_='hidden_1_1')
        words = soup.select('span.hidden_1_1')
        for word in words:
            if len(word)>0:
                print(word.string)



if __name__=="__main__":

    # http://job.qsbdc.com/word_list.php?book_id=952-1168
    #http: // job.qsbdc.com / word_list.php?book_id = 1167 & & page_id = 2
    getRelativeUrl()
    # url1 = 'http://job.qsbdc.com/word_list.php?book_id=952& & page_id = 1'
    # # getHTMLText(url)
    # getContentOfCom(url1)
    print("Ok, finish, perfect")
